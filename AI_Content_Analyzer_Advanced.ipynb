{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0246746c",
   "metadata": {},
   "source": [
    "# Advanced AI Content Analysis\n",
    "Using LDA, BERTopic, GPT-4 topic labeling, and comparative visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d6849",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0366a19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP & Topic Modeling\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Generative AI\n",
    "import openai\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96ae57",
   "metadata": {},
   "source": [
    "## 2. Configuration: Folders & Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c79007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuration: Folders & Keywords\n",
    "FOLDER_PATHS = {\n",
    "    \"Part 1\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_1\",\n",
    "    \"Part 2\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_2\",\n",
    "    \"Part 3\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_3\",\n",
    "    \"Part 4\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_4\"\n",
    "}\n",
    "\n",
    "# Comprehensive AI-related keywords\n",
    "AI_KEYWORDS = {\n",
    "    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural network\", \"generative ai\",\n",
    "    \"supervised learning\", \"unsupervised learning\", \"reinforcement learning\", \"transfer learning\",\n",
    "    \"federated learning\", \"attention mechanism\", \"llm\", \"gpt\", \"bert\", \"diffusion model\", \"gan\", \"rnn\", \"cnn\",\n",
    "    \"vlm\", \"gpt-4v\", \"llava\", \"nlp\", \"computer vision\", \"speech recognition\", \"autonomous systems\",\n",
    "    \"recommender system\", \"robotic process automation\", \"tensorflow\", \"pytorch\", \"keras\", \"huggingface\",\n",
    "    \"langchain\", \"openai\", \"anthropic\", \"mistral ai\", \"agi\", \"multimodal ai\", \"few-shot learning\",\n",
    "    \"prompt engineering\", \"retrieval-augmented generation\", \"ai agents\", \"autonomous agents\",\n",
    "    \"multi-agent systems\", \"embodied ai\", \"agent tool use\", \"llamaindex\", \"crewai\", \"autogen\", \"agentops\",\n",
    "    \"semantic kernel\", \"haystack\", \"weaviate\", \"pinecone\", \"qdrant\", \"chroma\", \"transformers\", \"peft\",\n",
    "    \"fastapi\", \"gradio\", \"streamlit\", \"guardrails\", \"rebuff\", \"guidance\", \"openai api\", \"gpt-4\",\n",
    "    \"gpt-4-turbo\", \"embeddings\", \"moderation\", \"anthropic claude api\", \"claude 3\", \"google vertex ai\",\n",
    "    \"palm 2\", \"gemini\", \"mistral ai api\", \"mistral 7b\", \"mixtral 8x7b\", \"cohere api\", \"command-r\",\n",
    "    \"meta llama api\", \"llama 2\", \"llama 3\", \"perplexity api\", \"openai gpt-4v\", \"google gemini api\",\n",
    "    \"anthropic claude 3 vision\", \"huggingface inference api\", \"blip-2\", \"llava\", \"openai whisper\",\n",
    "    \"elevenlabs\", \"deepgram\", \"assemblyai\", \"google cloud vision\", \"aws rekognition\",\n",
    "    \"azure computer vision\", \"roboflow\", \"openai embeddings\", \"cohere embed\", \"langchain api\",\n",
    "    \"stability ai\", \"microsoft semantic kernel\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b9820",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd6aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> list[str]:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english')) - {'ai'}\n",
    "    return [w for w in tokens if w not in stop_words and len(w) > 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6f58d",
   "metadata": {},
   "source": [
    "## 4. Load Documents from Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2921f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw text per folder\n",
    "documents_by_folder = {}\n",
    "for label, path in FOLDER_PATHS.items():\n",
    "    docs = []\n",
    "    for fname in os.listdir(path):\n",
    "        if fname.lower().endswith('.txt'):\n",
    "            with open(os.path.join(path, fname), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                docs.append(f.read())\n",
    "    documents_by_folder[label] = docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f2d8d",
   "metadata": {},
   "source": [
    "## 5. LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182f4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 LDA coherence: 0.5863\n",
      "(0, '0.007*\"file\" + 0.006*\"files\" + 0.005*\"annotations\" + 0.005*\"engl\" + 0.004*\"one\" + 0.004*\"see\" + 0.004*\"part\" + 0.004*\"code\" + 0.003*\"etc\" + 0.003*\"also\"')\n",
      "(1, '0.025*\"page\" + 0.016*\"images\" + 0.015*\"hathitrust\" + 0.009*\"de\" + 0.008*\"company\" + 0.008*\"co\" + 0.006*\"catalogue\" + 0.006*\"library\" + 0.006*\"la\" + 0.005*\"collection\"')\n",
      "(2, '0.065*\"images\" + 0.065*\"page\" + 0.065*\"hathitrust\" + 0.022*\"de\" + 0.009*\"history\" + 0.008*\"la\" + 0.007*\"et\" + 0.006*\"der\" + 0.006*\"des\" + 0.005*\"us\"')\n",
      "(3, '0.009*\"pdf\" + 0.007*\"phd\" + 0.006*\"university\" + 0.006*\"health\" + 0.006*\"view\" + 0.005*\"professor\" + 0.005*\"learning\" + 0.004*\"article\" + 0.004*\"study\" + 0.004*\"california\"')\n",
      "(4, '0.018*\"ai\" + 0.008*\"data\" + 0.007*\"use\" + 0.007*\"learning\" + 0.005*\"models\" + 0.005*\"using\" + 0.004*\"information\" + 0.004*\"tools\" + 0.004*\"generative\" + 0.004*\"language\"')\n",
      "(5, '0.010*\"reply\" + 0.005*\"one\" + 0.005*\"pm\" + 0.005*\"like\" + 0.004*\"people\" + 0.004*\"time\" + 0.004*\"said\" + 0.004*\"would\" + 0.004*\"get\" + 0.003*\"also\"')\n",
      "(6, '0.013*\"research\" + 0.011*\"university\" + 0.010*\"science\" + 0.008*\"professor\" + 0.008*\"engineering\" + 0.006*\"school\" + 0.006*\"education\" + 0.005*\"faculty\" + 0.005*\"teaching\" + 0.005*\"college\"')\n",
      "(7, '0.014*\"students\" + 0.012*\"course\" + 0.006*\"business\" + 0.006*\"student\" + 0.005*\"law\" + 0.005*\"online\" + 0.005*\"program\" + 0.005*\"may\" + 0.005*\"management\" + 0.005*\"academic\"')\n",
      "\n",
      "Part 2 LDA coherence: 0.5481\n",
      "(0, '0.024*\"pm\" + 0.010*\"february\" + 0.010*\"view\" + 0.009*\"pubmed\" + 0.009*\"pmid\" + 0.007*\"health\" + 0.006*\"speaker\" + 0.006*\"undergraduate\" + 0.006*\"room\" + 0.005*\"center\"')\n",
      "(1, '0.026*\"cancer\" + 0.026*\"maughan\" + 0.019*\"article\" + 0.019*\"bl\" + 0.018*\"full\" + 0.018*\"read\" + 0.015*\"prostate\" + 0.013*\"agarwal\" + 0.010*\"center\" + 0.010*\"metastatic\"')\n",
      "(2, '0.019*\"engineering\" + 0.016*\"professor\" + 0.016*\"science\" + 0.012*\"research\" + 0.009*\"university\" + 0.009*\"institute\" + 0.009*\"college\" + 0.008*\"computer\" + 0.008*\"department\" + 0.008*\"school\"')\n",
      "(3, '0.016*\"ai\" + 0.009*\"data\" + 0.005*\"research\" + 0.004*\"using\" + 0.004*\"use\" + 0.004*\"article\" + 0.004*\"models\" + 0.003*\"generative\" + 0.003*\"date\" + 0.003*\"learning\"')\n",
      "(4, '0.014*\"learn\" + 0.013*\"communication\" + 0.012*\"research\" + 0.011*\"read\" + 0.010*\"media\" + 0.010*\"public\" + 0.009*\"advertising\" + 0.009*\"students\" + 0.007*\"university\" + 0.007*\"grady\"')\n",
      "(5, '0.008*\"people\" + 0.007*\"business\" + 0.006*\"know\" + 0.006*\"like\" + 0.006*\"also\" + 0.005*\"one\" + 0.005*\"time\" + 0.005*\"really\" + 0.005*\"white\" + 0.005*\"ken\"')\n",
      "(6, '0.020*\"students\" + 0.016*\"course\" + 0.009*\"student\" + 0.009*\"work\" + 0.008*\"may\" + 0.007*\"use\" + 0.007*\"learning\" + 0.006*\"information\" + 0.005*\"teaching\" + 0.005*\"faculty\"')\n",
      "(7, '0.018*\"page\" + 0.017*\"images\" + 0.016*\"hathitrust\" + 0.007*\"us\" + 0.006*\"de\" + 0.006*\"states\" + 0.006*\"united\" + 0.005*\"library\" + 0.004*\"american\" + 0.004*\"history\"')\n",
      "\n",
      "Part 3 LDA coherence: 0.5740\n",
      "(0, '0.008*\"people\" + 0.006*\"one\" + 0.006*\"think\" + 0.006*\"white\" + 0.005*\"like\" + 0.005*\"know\" + 0.005*\"ken\" + 0.005*\"business\" + 0.005*\"us\" + 0.005*\"law\"')\n",
      "(1, '0.013*\"united\" + 0.012*\"states\" + 0.010*\"certificate\" + 0.010*\"online\" + 0.007*\"management\" + 0.007*\"masters\" + 0.006*\"islands\" + 0.005*\"oncampus\" + 0.005*\"new\" + 0.003*\"south\"')\n",
      "(2, '0.023*\"pubmed\" + 0.014*\"view\" + 0.014*\"al\" + 0.013*\"et\" + 0.011*\"id\" + 0.010*\"doi\" + 0.010*\"data\" + 0.010*\"structure\" + 0.010*\"file\" + 0.009*\"viewer\"')\n",
      "(3, '0.008*\"research\" + 0.007*\"health\" + 0.005*\"information\" + 0.004*\"data\" + 0.004*\"study\" + 0.003*\"studies\" + 0.003*\"time\" + 0.002*\"pm\" + 0.002*\"social\" + 0.002*\"medicine\"')\n",
      "(4, '0.053*\"page\" + 0.049*\"images\" + 0.047*\"hathitrust\" + 0.011*\"de\" + 0.009*\"us\" + 0.006*\"united\" + 0.006*\"london\" + 0.006*\"states\" + 0.005*\"la\" + 0.005*\"access\"')\n",
      "(5, '0.015*\"students\" + 0.014*\"course\" + 0.006*\"writing\" + 0.005*\"may\" + 0.005*\"use\" + 0.005*\"student\" + 0.004*\"work\" + 0.004*\"academic\" + 0.004*\"class\" + 0.004*\"learning\"')\n",
      "(6, '0.015*\"university\" + 0.010*\"pdf\" + 0.009*\"engineering\" + 0.008*\"conference\" + 0.008*\"science\" + 0.007*\"systems\" + 0.007*\"professor\" + 0.007*\"learning\" + 0.006*\"international\" + 0.006*\"computer\"')\n",
      "(7, '0.020*\"ai\" + 0.010*\"research\" + 0.008*\"data\" + 0.007*\"learning\" + 0.007*\"university\" + 0.005*\"students\" + 0.005*\"technology\" + 0.005*\"generative\" + 0.005*\"new\" + 0.004*\"information\"')\n",
      "\n",
      "Part 4 LDA coherence: 0.5118\n",
      "(0, '0.023*\"students\" + 0.018*\"course\" + 0.008*\"learning\" + 0.007*\"teaching\" + 0.006*\"student\" + 0.005*\"business\" + 0.005*\"program\" + 0.005*\"courses\" + 0.005*\"class\" + 0.005*\"data\"')\n",
      "(1, '0.026*\"ai\" + 0.009*\"use\" + 0.007*\"generative\" + 0.005*\"data\" + 0.005*\"tools\" + 0.005*\"using\" + 0.004*\"information\" + 0.004*\"work\" + 0.004*\"used\" + 0.004*\"like\"')\n",
      "(2, '0.013*\"systems\" + 0.012*\"research\" + 0.011*\"data\" + 0.011*\"science\" + 0.009*\"learning\" + 0.009*\"computer\" + 0.008*\"pdf\" + 0.007*\"conference\" + 0.007*\"information\" + 0.006*\"machine\"')\n",
      "(3, '0.031*\"engineering\" + 0.028*\"professor\" + 0.025*\"college\" + 0.020*\"science\" + 0.020*\"university\" + 0.014*\"department\" + 0.012*\"assistant\" + 0.011*\"education\" + 0.010*\"faculty\" + 0.010*\"school\"')\n",
      "(4, '0.009*\"research\" + 0.007*\"university\" + 0.007*\"program\" + 0.006*\"faculty\" + 0.006*\"student\" + 0.005*\"students\" + 0.005*\"pm\" + 0.005*\"health\" + 0.005*\"new\" + 0.004*\"school\"')\n",
      "(5, '0.013*\"page\" + 0.009*\"images\" + 0.008*\"hathitrust\" + 0.005*\"london\" + 0.004*\"printed\" + 0.004*\"england\" + 0.004*\"html\" + 0.004*\"john\" + 0.003*\"tcp\" + 0.003*\"eebo\"')\n",
      "(6, '0.013*\"dot\" + 0.012*\"health\" + 0.008*\"pmid\" + 0.008*\"pubmed\" + 0.007*\"care\" + 0.006*\"medical\" + 0.006*\"medicine\" + 0.006*\"clinical\" + 0.005*\"com\" + 0.005*\"patients\"')\n",
      "(7, '0.004*\"new\" + 0.004*\"us\" + 0.004*\"law\" + 0.003*\"also\" + 0.003*\"one\" + 0.003*\"people\" + 0.003*\"public\" + 0.003*\"world\" + 0.003*\"first\" + 0.003*\"global\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_results = {}\n",
    "for label, docs in documents_by_folder.items():\n",
    "    texts = [preprocess_text(doc) for doc in docs]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda = models.LdaModel(corpus, id2word=dictionary, num_topics=8, passes=10)\n",
    "    coherence = CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    lda_results[label] = {\n",
    "        'model': lda,\n",
    "        'dictionary': dictionary,\n",
    "        'corpus': corpus,\n",
    "        'coherence': coherence.get_coherence(),\n",
    "        'topics': lda.print_topics()\n",
    "    }\n",
    "    print(f\"{label} LDA coherence: {lda_results[label]['coherence']:.4f}\")\n",
    "    for topic in lda_results[label]['topics']:\n",
    "        print(topic)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f2ab2",
   "metadata": {},
   "source": [
    "## 6. BERTopic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63cd9908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 BERTopic extracted 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1975</td>\n",
       "      <td>-1_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, by, at, page, images, hathi...</td>\n",
       "      <td>[URL: https://firstyear.tulane.edu/fall-2024-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2381</td>\n",
       "      <td>0_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, on, is, at, with]</td>\n",
       "      <td>[URL: https://oregonnews.uoregon.edu/lccn/sn83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1_annotations_files_alignments_genome</td>\n",
       "      <td>[annotations, files, alignments, genome, etc, ...</td>\n",
       "      <td>[URL: https://digital.wpi.edu/catalog?f%5Bmemb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                   Name  \\\n",
       "0     -1   1975                       -1_the_and_of_to   \n",
       "1      0   2381                        0_the_and_of_to   \n",
       "2      1     14  1_annotations_files_alignments_genome   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [the, and, of, to, by, at, page, images, hathi...   \n",
       "1      [the, and, of, to, in, for, on, is, at, with]   \n",
       "2  [annotations, files, alignments, genome, etc, ...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [URL: https://firstyear.tulane.edu/fall-2024-t...  \n",
       "1  [URL: https://oregonnews.uoregon.edu/lccn/sn83...  \n",
       "2  [URL: https://digital.wpi.edu/catalog?f%5Bmemb...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 BERTopic extracted 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2550</td>\n",
       "      <td>-1_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, is, that, by, on]</td>\n",
       "      <td>[URL: https://history.northwestern.edu/courses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1446</td>\n",
       "      <td>0_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, that, you, is, with]</td>\n",
       "      <td>[URL: https://teaching.uoregon.edu/starter-syl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1_the_to_of_ai</td>\n",
       "      <td>[the, to, of, ai, and, in, is, that, for, on]</td>\n",
       "      <td>[URL: https://insights.sei.cmu.edu/blog/contex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count              Name  \\\n",
       "0     -1   2550  -1_the_and_of_to   \n",
       "1      0   1446   0_the_and_of_to   \n",
       "2      1     19    1_the_to_of_ai   \n",
       "\n",
       "                                     Representation  \\\n",
       "0     [the, and, of, to, in, for, is, that, by, on]   \n",
       "1  [the, and, of, to, in, for, that, you, is, with]   \n",
       "2     [the, to, of, ai, and, in, is, that, for, on]   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [URL: https://history.northwestern.edu/courses...  \n",
       "1  [URL: https://teaching.uoregon.edu/starter-syl...  \n",
       "2  [URL: https://insights.sei.cmu.edu/blog/contex...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 BERTopic extracted 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2012</td>\n",
       "      <td>-1_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, by, at, page, images]</td>\n",
       "      <td>[URL: https://as.vanderbilt.edu/english/underg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2330</td>\n",
       "      <td>0_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, that, is, you, with]</td>\n",
       "      <td>[URL: https://physics.as.miami.edu/research/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1_privacy_agree_to_commitment</td>\n",
       "      <td>[privacy, agree, to, commitment, vcus, commonw...</td>\n",
       "      <td>[URL: https://go.vcu.edu/ai\\nTitle: Commitment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   2012               -1_the_and_of_to   \n",
       "1      0   2330                0_the_and_of_to   \n",
       "2      1     17  1_privacy_agree_to_commitment   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [the, and, of, to, in, for, by, at, page, images]   \n",
       "1   [the, and, of, to, in, for, that, is, you, with]   \n",
       "2  [privacy, agree, to, commitment, vcus, commonw...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [URL: https://as.vanderbilt.edu/english/underg...  \n",
       "1  [URL: https://physics.as.miami.edu/research/ne...  \n",
       "2  [URL: https://go.vcu.edu/ai\\nTitle: Commitment...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4 BERTopic extracted 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1424</td>\n",
       "      <td>-1_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, is, on, that, ai]</td>\n",
       "      <td>[URL: http://lrieber.coe.uga.edu/mayer2005/\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2944</td>\n",
       "      <td>0_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, in, for, is, with, that, on]</td>\n",
       "      <td>[URL: https://oregonnews.uoregon.edu/lccn/sn83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1_privacy_agree_commitment_to</td>\n",
       "      <td>[privacy, agree, commitment, to, vcus, cookies...</td>\n",
       "      <td>[URL: https://graduate.vcu.edu/\\nTitle: Commit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   1424               -1_the_and_of_to   \n",
       "1      0   2944                0_the_and_of_to   \n",
       "2      1     28  1_privacy_agree_commitment_to   \n",
       "\n",
       "                                      Representation  \\\n",
       "0      [the, and, of, to, in, for, is, on, that, ai]   \n",
       "1    [the, and, of, to, in, for, is, with, that, on]   \n",
       "2  [privacy, agree, commitment, to, vcus, cookies...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [URL: http://lrieber.coe.uga.edu/mayer2005/\\nT...  \n",
       "1  [URL: https://oregonnews.uoregon.edu/lccn/sn83...  \n",
       "2  [URL: https://graduate.vcu.edu/\\nTitle: Commit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bertopic_results = {}\n",
    "for label, docs in documents_by_folder.items():\n",
    "    topic_model = BERTopic(verbose=False)\n",
    "    topics, probs = topic_model.fit_transform(docs)\n",
    "    # compute an approximate coherence via class-based TF-IDF topic keywords\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    bertopic_results[label] = {\n",
    "        'model': topic_model,\n",
    "        'topics': topic_info.head(10)\n",
    "    }\n",
    "    print(f\"{label} BERTopic extracted {topic_info.shape[0]-1} topics\")\n",
    "    display(topic_info.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde94e4f",
   "metadata": {},
   "source": [
    "## 7. GPT-4 Topic Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6bb54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (1.7.0)\n",
      "Requirement already satisfied: torch in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91756\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7afc8cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n401 Client Error. (Request ID: Root=1-682716db-7627e1d11bfc948821111341;87599f87-5c2a-427d-969f-59859a61572f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     hf_hub_download(\n\u001b[0;32m    425\u001b[0m         path_or_repo_id,\n\u001b[0;32m    426\u001b[0m         filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    427\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    428\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    429\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    430\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    431\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    432\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    433\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    434\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    435\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    436\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    437\u001b[0m     )\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    963\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m    965\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m    966\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    967\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    968\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    969\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m    970\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m    971\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m    972\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m    973\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    974\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m    976\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    977\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    978\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1593\u001b[0m ):\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1485\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[0;32m   1486\u001b[0m     )\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1402\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1403\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1404\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m   1405\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1406\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1407\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1408\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1409\u001b[0m )\n\u001b[0;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    287\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    288\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 309\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_http.py:426\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    423\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m     )\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-682716db-7627e1d11bfc948821111341;87599f87-5c2a-427d-969f-59859a61572f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ─── 1) Initialize the local chat model ─────────────────────────────────────────\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Adjust `model_name` if you choose a different HF model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m chat \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m     13\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# some chat models need this\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# ─── 2) Define the topic‐labeling function ────────────────────────────────────────\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlabel_topics_local\u001b[39m(docs, n_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py:851\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    848\u001b[0m                 adapter_path \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    849\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 851\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    852\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    853\u001b[0m     )\n\u001b[0;32m    854\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    856\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1114\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1112\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1114\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1115\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1116\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\configuration_utils.py:590\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    588\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 649\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    650\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    651\u001b[0m         configuration_file,\n\u001b[0;32m    652\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    653\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    654\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    655\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    656\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    657\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    658\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    659\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    660\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    661\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    662\u001b[0m     )\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:481\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    484\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n401 Client Error. (Request ID: Root=1-682716db-7627e1d11bfc948821111341;87599f87-5c2a-427d-969f-59859a61572f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# ─── 1) Initialize the local chat model ─────────────────────────────────────────\n",
    "# Adjust `model_name` if you choose a different HF model\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "chat = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True  # some chat models need this\n",
    ")\n",
    "\n",
    "# ─── 2) Define the topic‐labeling function ────────────────────────────────────────\n",
    "def label_topics_local(docs, n_topics=5):\n",
    "    \"\"\"\n",
    "    Uses a local LLM to identify the top `n_topics` topics in `docs`.\n",
    "    Returns a dict: {\"topic_1\": [...], \"topic_2\": [...], ...}.\n",
    "    \"\"\"\n",
    "    # Prepare a short sample of up to 10 docs, 500 chars each\n",
    "    sample_lines = []\n",
    "    for d in docs[:10]:\n",
    "        clean = d.replace(\"\\n\", \" \")[:500]\n",
    "        sample_lines.append(f\"- {clean}\")\n",
    "    sample = \"\\n\".join(sample_lines)\n",
    "\n",
    "    # Construct the prompt (double‐brace JSON skeleton)\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant. Given the following documents, identify the top {n_topics} topics,\n",
    "each with 3–5 keywords. Return **only** valid JSON of the form {{\"topic_1\": [\"kw1\",\"kw2\"], ...}}.\n",
    "\n",
    "Documents:\n",
    "{sample}\n",
    "\"\"\"\n",
    "    # Invoke the model\n",
    "    out = chat(prompt, max_new_tokens=256, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "    # Extract the JSON blob\n",
    "    match = re.search(r\"\\{.*\\}\", out, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not parse JSON from model output:\\n{out}\")\n",
    "    return json.loads(match.group(0))\n",
    "\n",
    "# ─── 3) Example usage over your foldered documents ────────────────────────────────\n",
    "# Assume you already have: documents_by_folder: dict[str, list[str]]\n",
    "# e.g. documents_by_folder = {\"Part 1\": [...], ...}\n",
    "\n",
    "gpt4_labels_local = {}\n",
    "for label, docs in documents_by_folder.items():\n",
    "    print(f\"🔍 Labeling {label} with local LLM…\")\n",
    "    try:\n",
    "        labels = label_topics_local(docs, n_topics=5)\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Error on {label}: {e}\")\n",
    "        labels = {}\n",
    "    gpt4_labels_local[label] = labels\n",
    "    print(json.dumps(labels, indent=2))\n",
    "\n",
    "# Now gpt4_labels_local holds your topic→keywords mappings per folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5293f8",
   "metadata": {},
   "source": [
    "## 8. Comparison & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LDA coherence\n",
    "lda_coherence = {lbl: res['coherence'] for lbl, res in lda_results.items()}\n",
    "plt.figure(figsize=(6,4))\n",
    "pd.Series(lda_coherence).plot.bar()\n",
    "plt.title('LDA Coherence by Folder')\n",
    "plt.ylabel('Coherence (c_v)')\n",
    "plt.show()\n",
    "\n",
    "# BERTopic topic counts\n",
    "ber_counts = {lbl: res['topics'].shape[0]-1 for lbl, res in bertopic_results.items()}\n",
    "plt.figure(figsize=(6,4))\n",
    "pd.Series(ber_counts).plot.bar(color='green')\n",
    "plt.title('BERTopic Number of Topics by Folder')\n",
    "plt.ylabel('Number of Topics')\n",
    "plt.show()\n",
    "\n",
    "# Display GPT-4 labels\n",
    "for lbl, topics in gpt4_labels.items():\n",
    "    print(f\"### {lbl} GPT-4 Topics\")\n",
    "    display(pd.DataFrame.from_dict(topics, orient='index', columns=['keywords']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f8030",
   "metadata": {},
   "source": [
    "## 9. Word Clouds from LDA & BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084bda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA topic word clouds\n",
    "for lbl, res in lda_results.items():\n",
    "    for tid, t in res['model'].show_topics(formatted=False):\n",
    "        words = dict(t)\n",
    "        wc = WordCloud(width=400, height=300).generate_from_frequencies(words)\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{lbl} LDA Topic {tid}\")\n",
    "        plt.show()\n",
    "\n",
    "# BERTopic topic word clouds\n",
    "for lbl, res in bertopic_results.items():\n",
    "    topics = res['model'].get_topics()\n",
    "    for tid in list(topics.keys())[:5]:\n",
    "        wc = WordCloud(width=400, height=300).generate_from_frequencies(dict(topics[tid]))\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{lbl} BERTopic {tid}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
