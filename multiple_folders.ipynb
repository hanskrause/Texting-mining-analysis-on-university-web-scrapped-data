{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30ace8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing: Part 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing parsed_content_links_list_part_1: 100%|██████████| 4370/4370 [00:24<00:00, 175.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI CONTENT ANALYSIS REPORT\n",
      "========================================\n",
      "Total files analyzed: 4370\n",
      "Files containing AI content: 2564 (58.7%)\n",
      "Average AI content %: 1.20%\n",
      "\n",
      "Top 5 files by AI %:\n",
      "Filename  AI_Percentage  AI_Word_Count\n",
      "1555.txt      23.076923              3\n",
      "1014.txt      16.666667              4\n",
      "2875.txt      16.528926             20\n",
      "4297.txt      15.032680             23\n",
      " 587.txt      14.432990             28\n",
      "\n",
      "Top 10 AI terms:\n",
      "[('ai', 26755), ('llm', 1016), ('guidance', 1000), ('gpt', 734), ('nlp', 703), ('openai', 395), ('embeddings', 362), ('bert', 361), ('transformers', 261), ('gemini', 206)]\n",
      "\n",
      "Results saved in: C:\\Users\\91756\\Downloads\\Master_thesis\\results\\Part_1\n",
      "\n",
      "\n",
      "--- Processing: Part 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing parsed_content_links_list_part_2: 100%|██████████| 4015/4015 [00:22<00:00, 177.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI CONTENT ANALYSIS REPORT\n",
      "========================================\n",
      "Total files analyzed: 4015\n",
      "Files containing AI content: 2461 (61.3%)\n",
      "Average AI content %: 1.29%\n",
      "\n",
      "Top 5 files by AI %:\n",
      " Filename  AI_Percentage  AI_Word_Count\n",
      " 5693.txt      29.411765              5\n",
      "10242.txt      20.000000              2\n",
      " 7585.txt      17.266187             24\n",
      " 7478.txt      16.393443             20\n",
      " 6229.txt      13.953488             12\n",
      "\n",
      "Top 10 AI terms:\n",
      "[('ai', 27949), ('guidance', 1005), ('gpt', 715), ('llm', 518), ('openai', 463), ('nlp', 366), ('gemini', 182), ('transformers', 107), ('embeddings', 90), ('moderation', 87)]\n",
      "\n",
      "Results saved in: C:\\Users\\91756\\Downloads\\Master_thesis\\results\\Part_2\n",
      "\n",
      "\n",
      "--- Processing: Part 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing parsed_content_links_list_part_3: 100%|██████████| 4359/4359 [00:25<00:00, 167.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI CONTENT ANALYSIS REPORT\n",
      "========================================\n",
      "Total files analyzed: 4359\n",
      "Files containing AI content: 2656 (60.9%)\n",
      "Average AI content %: 1.24%\n",
      "\n",
      "Top 5 files by AI %:\n",
      " Filename  AI_Percentage  AI_Word_Count\n",
      "12612.txt      24.000000              6\n",
      "11452.txt      19.230769             25\n",
      "15163.txt      16.793893             22\n",
      "14484.txt      16.406250             21\n",
      "15211.txt      14.953271             16\n",
      "\n",
      "Top 10 AI terms:\n",
      "[('ai', 27515), ('guidance', 977), ('gpt', 716), ('llm', 681), ('openai', 538), ('nlp', 333), ('gemini', 271), ('transformers', 155), ('gan', 85), ('moderation', 84)]\n",
      "\n",
      "Results saved in: C:\\Users\\91756\\Downloads\\Master_thesis\\results\\Part_3\n",
      "\n",
      "\n",
      "--- Processing: Part 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing parsed_content_links_list_part_4: 100%|██████████| 4396/4396 [00:28<00:00, 154.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI CONTENT ANALYSIS REPORT\n",
      "========================================\n",
      "Total files analyzed: 4396\n",
      "Files containing AI content: 2640 (60.1%)\n",
      "Average AI content %: 1.26%\n",
      "\n",
      "Top 5 files by AI %:\n",
      " Filename  AI_Percentage  AI_Word_Count\n",
      "19535.txt      25.000000              3\n",
      "16843.txt      23.076923              3\n",
      "21104.txt      20.000000              2\n",
      "18024.txt      20.000000              2\n",
      "19069.txt      16.666667             28\n",
      "\n",
      "Top 10 AI terms:\n",
      "[('ai', 28649), ('guidance', 1273), ('llm', 1092), ('gpt', 657), ('openai', 432), ('nlp', 386), ('gemini', 201), ('transformers', 112), ('embeddings', 80), ('cnn', 74)]\n",
      "\n",
      "Results saved in: C:\\Users\\91756\\Downloads\\Master_thesis\\results\\Part_4\n",
      "\n",
      "\n",
      "=== Summary Comparison ===\n",
      "        Total Files  Avg AI %  % Files w/ AI\n",
      "Folder                                      \n",
      "Part 1         4370  1.198520      58.672769\n",
      "Part 2         4015  1.291634      61.295143\n",
      "Part 3         4359  1.242018      60.931406\n",
      "Part 4         4396  1.255026      60.054595\n",
      "\n",
      "Comparative plots saved in 'results/'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download NLTK data if not already present\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# ─── Configuration ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# Folders to analyze\n",
    "FOLDER_PATHS = {\n",
    "    \"Part 1\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_1\",\n",
    "    \"Part 2\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_2\",\n",
    "    \"Part 3\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_3\",\n",
    "    \"Part 4\": r\"C:\\Users\\91756\\Downloads\\Master_thesis\\Parsed_Content\\Parsed_Content\\parsed_content_links_list_part_4\"\n",
    "}\n",
    "\n",
    "# Comprehensive AI-related keywords\n",
    "AI_KEYWORDS = {\n",
    "    # Core AI Terms\n",
    "    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural network\", \"generative ai\",\n",
    "    # AI Techniques & Methods\n",
    "    \"supervised learning\", \"unsupervised learning\", \"reinforcement learning\", \"transfer learning\",\n",
    "    \"federated learning\", \"attention mechanism\",\n",
    "    # AI Model Types\n",
    "    \"llm\", \"gpt\", \"bert\", \"diffusion model\", \"gan\", \"rnn\", \"cnn\", \"vlm\", \"gpt-4v\", \"llava\",\n",
    "    # AI Applications\n",
    "    \"nlp\", \"computer vision\", \"speech recognition\", \"autonomous systems\", \"recommender system\", \"robotic process automation\",\n",
    "    # AI Tools & Frameworks\n",
    "    \"tensorflow\", \"pytorch\", \"keras\", \"huggingface\", \"langchain\", \"openai\", \"anthropic\", \"mistral ai\",\n",
    "    # Emerging AI Concepts\n",
    "    \"agi\", \"multimodal ai\", \"few-shot learning\", \"prompt engineering\", \"retrieval-augmented generation\",\n",
    "    # Agent Ecosystem\n",
    "    \"ai agents\", \"autonomous agents\", \"multi-agent systems\", \"embodied ai\", \"agent tool use\",\n",
    "    # Libraries & Frameworks for AI Agents\n",
    "    \"llamaindex\", \"crewai\", \"autogen\", \"agentops\", \"semantic kernel\", \"haystack\",\n",
    "    \"weaviate\", \"pinecone\", \"qdrant\", \"chroma\", \"transformers\", \"peft\", \"fastapi\",\n",
    "    \"gradio\", \"streamlit\", \"guardrails\", \"rebuff\", \"guidance\",\n",
    "    # AI APIs\n",
    "    \"openai api\", \"gpt-4\", \"gpt-4-turbo\", \"embeddings\", \"moderation\",\n",
    "    \"anthropic claude api\", \"claude 3\", \"google vertex ai\", \"palm 2\", \"gemini\",\n",
    "    \"mistral ai api\", \"mistral 7b\", \"mixtral 8x7b\", \"cohere api\", \"command-r\",\n",
    "    \"meta llama api\", \"llama 2\", \"llama 3\", \"perplexity api\",\n",
    "    \"openai gpt-4v\", \"google gemini api\", \"anthropic claude 3 vision\",\n",
    "    \"huggingface inference api\", \"blip-2\", \"llava\",\n",
    "    \"openai whisper\", \"elevenlabs\", \"deepgram\", \"assemblyai\",\n",
    "    \"google cloud vision\", \"aws rekognition\", \"azure computer vision\",\n",
    "    \"roboflow\", \"openai embeddings\", \"cohere embed\",\n",
    "    \"langchain api\", \"stability ai\", \"microsoft semantic kernel\"\n",
    "}\n",
    "\n",
    "# ─── Helper Functions ────────────────────────────────────────────────────────────\n",
    "\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    \"\"\"Lowercase, strip non-alpha, tokenize and remove stopwords (except 'ai').\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english')) - {'ai'}\n",
    "    return [w for w in tokens if w not in stop_words and len(w) > 1]\n",
    "\n",
    "def analyze_ai_content(file_path: str) -> tuple[float, list[str]]:\n",
    "    \"\"\"Return (AI_percentage, list_of_ai_words) for a single text file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        if not content.strip():\n",
    "            return 0.0, []\n",
    "        words = preprocess_text(content)\n",
    "        if len(words) < 10:\n",
    "            return 0.0, []\n",
    "        ai_words = [w for w in words if w in AI_KEYWORDS]\n",
    "        ai_pct = len(ai_words) / len(words) * 100\n",
    "        return ai_pct, ai_words\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {os.path.basename(file_path)}: {e}\")\n",
    "        return 0.0, []\n",
    "\n",
    "def analyze_files(folder_path: str, max_files: int = None) -> tuple[pd.DataFrame, list[str]]:\n",
    "    \"\"\"Analyze all .txt files in folder; return DataFrame and aggregated AI words.\"\"\"\n",
    "    results = []\n",
    "    all_ai_words: list[str] = []\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith('.txt')])\n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    for fname in tqdm(files, desc=f\"Analyzing {os.path.basename(folder_path)}\"):\n",
    "        full = os.path.join(folder_path, fname)\n",
    "        pct, words = analyze_ai_content(full)\n",
    "        results.append({\n",
    "            \"Filename\": fname,\n",
    "            \"AI_Percentage\": pct,\n",
    "            \"AI_Word_Count\": len(words)\n",
    "        })\n",
    "        all_ai_words.extend(words)\n",
    "    return pd.DataFrame(results), all_ai_words\n",
    "\n",
    "def create_visualizations(df: pd.DataFrame, ai_words: list[str], output_dir: str):\n",
    "    \"\"\"Save histogram, bar-chart, pie and word-cloud to output_dir.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Histogram: AI %\n",
    "    plt.subplot(2, 2, 1)\n",
    "    df['AI_Percentage'].plot.hist(bins=20, edgecolor='black')\n",
    "    plt.title('Distribution of AI Content %')\n",
    "    plt.xlabel('AI %')\n",
    "    plt.ylabel('File Count')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Bar chart: Top AI terms\n",
    "    plt.subplot(2, 2, 2)\n",
    "    top = pd.DataFrame(Counter(ai_words).most_common(10), columns=['Word', 'Count'])\n",
    "    top.plot.barh(x='Word', y='Count', legend=False, ax=plt.gca())\n",
    "    plt.title('Top 10 AI Terms')\n",
    "    plt.xlabel('Frequency')\n",
    "\n",
    "    # Pie: files with AI\n",
    "    plt.subplot(2, 2, 3)\n",
    "    has_ai = len(df[df['AI_Word_Count'] > 0])\n",
    "    plt.pie([has_ai, len(df)-has_ai],\n",
    "            labels=['Contains AI', 'No AI'],\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "    plt.title('Files Containing AI')\n",
    "\n",
    "    # Word Cloud\n",
    "    plt.subplot(2, 2, 4)\n",
    "    wc = WordCloud(width=800, height=500, background_color='white')\n",
    "    wc.generate(' '.join(ai_words))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('AI Terms Word Cloud')\n",
    "\n",
    "    plt.tight_layout(pad=3)\n",
    "    plt.savefig(os.path.join(output_dir, 'visualizations.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def generate_report(df: pd.DataFrame, ai_words: list[str], output_dir: str):\n",
    "    \"\"\"Write CSV, text report and print summary to console.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df.to_csv(os.path.join(output_dir, 'ai_content_analysis.csv'), index=False)\n",
    "    total = len(df)\n",
    "    with_ai = len(df[df['AI_Word_Count'] > 0])\n",
    "    avg_pct = df['AI_Percentage'].mean()\n",
    "    report = (\n",
    "        f\"AI CONTENT ANALYSIS REPORT\\n\"\n",
    "        f\"{'='*40}\\n\"\n",
    "        f\"Total files analyzed: {total}\\n\"\n",
    "        f\"Files containing AI content: {with_ai} ({with_ai/total*100:.1f}%)\\n\"\n",
    "        f\"Average AI content %: {avg_pct:.2f}%\\n\\n\"\n",
    "        \"Top 5 files by AI %:\\n\"\n",
    "        f\"{df.sort_values('AI_Percentage', ascending=False).head(5).to_string(index=False)}\\n\\n\"\n",
    "        \"Top 10 AI terms:\\n\"\n",
    "        f\"{Counter(ai_words).most_common(10)}\\n\"\n",
    "    )\n",
    "    with open(os.path.join(output_dir, 'report.txt'), 'w') as f:\n",
    "        f.write(report)\n",
    "    print(report)\n",
    "    print(f\"Results saved in: {os.path.abspath(output_dir)}\\n\")\n",
    "\n",
    "# ─── Main Execution ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    folder_stats = {}\n",
    "    # Analyze each folder independently\n",
    "    for label, path in FOLDER_PATHS.items():\n",
    "        print(f\"\\n--- Processing: {label} ---\")\n",
    "        df, words = analyze_files(path)\n",
    "        out_dir = os.path.join(\"results\", label.replace(\" \", \"_\"))\n",
    "        create_visualizations(df, words, out_dir)\n",
    "        generate_report(df, words, out_dir)\n",
    "        folder_stats[label] = {\n",
    "            \"df\": df,\n",
    "            \"words\": words,\n",
    "            \"avg_pct\": df['AI_Percentage'].mean(),\n",
    "            \"pct_with_ai\": len(df[df['AI_Word_Count']>0]) / len(df) * 100,\n",
    "            \"total\": len(df)\n",
    "        }\n",
    "\n",
    "    # Comparison summary\n",
    "    summary = pd.DataFrame([\n",
    "        {\n",
    "            \"Folder\": lbl,\n",
    "            \"Total Files\": stats[\"total\"],\n",
    "            \"Avg AI %\": stats[\"avg_pct\"],\n",
    "            \"% Files w/ AI\": stats[\"pct_with_ai\"]\n",
    "        }\n",
    "        for lbl, stats in folder_stats.items()\n",
    "    ]).set_index(\"Folder\")\n",
    "\n",
    "    # Save and display summary\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    summary.to_csv(os.path.join(\"results\", \"summary_comparison.csv\"))\n",
    "    print(\"\\n=== Summary Comparison ===\")\n",
    "    print(summary)\n",
    "\n",
    "    # Comparative plots\n",
    "    plt.figure(figsize=(8,4))\n",
    "    summary['Avg AI %'].plot.bar()\n",
    "    plt.title(\"Average AI % by Folder\")\n",
    "    plt.ylabel(\"Avg AI %\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/avg_ai_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    summary['% Files w/ AI'].plot.bar(color='orange')\n",
    "    plt.title(\"% Files with AI by Folder\")\n",
    "    plt.ylabel(\"% Files w/ AI\")\n",
    "    plt.ylim(0,100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/pct_with_ai_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nComparative plots saved in 'results/'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16d84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
